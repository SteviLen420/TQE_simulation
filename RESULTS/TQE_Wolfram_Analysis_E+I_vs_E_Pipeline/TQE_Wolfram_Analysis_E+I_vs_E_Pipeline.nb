(* SPDX-License-Identifier: MIT *)
(* Copyright (c) 2025 Stefan Len *)

(* =================================================================================== *)
(* TQE_Wolfram_Analysis_E+I_vs_E_Pipeline.nb *)
(* =================================================================================== *)
(* Author: Stefan Len *)
(* =================================================================================== *)

(* ============================= *)
(* 1) SET INPUT DIRECTORIES      *)
(* ============================= *)

dirA = "/Users/stevilen/Desktop/TQE_COMBINED_CSV/dataset_A_E+I";
dirB = "/Users/stevilen/Desktop/TQE_COMBINED_CSV/dataset_B_E_only";

(* ============================= *)
(* 2) HELPER FUNCTIONS           *)
(* ============================= *)

ClearAll[say, safeImport, toDS, pickCol, binStats, pct, niceName, tryCols, colExistsQ];

(* Pretty printing for headers *)
say[txt_] := Print[Style[txt, 14, Bold, RGBColor[0.1, 0.2, 0.6]]];

(* Explicit CSV import -> raw rows -> wrap into Dataset *)
safeImport[f_] := Quiet@Check[
  Dataset @ Import[f, {"CSV","Data"}],
  Missing["NotAvailable"]
];

(* Ensure input is a Dataset *)
toDS[x_] := Which[
  Head[x] === Dataset, x,
  MatchQ[x, _List], Dataset[x],
  True, Missing["NotAvailable"]
];

(* Check if a column exists in dataset *)
colExistsQ[ds_, name_] := Module[{ok = MatchQ[ds, _Dataset] && Length[ds] > 0},
  If[!ok, False, Quiet@Check[KeyExistsQ[Normal@First@ds, name], False]]
];

(* Try multiple column name candidates *)
tryCols[ds_, names_List] := With[
  {hit = SelectFirst[names, colExistsQ[ds, #] & , None]},
  If[hit === None, Missing["NotAvailable"], ds[All, hit]]
];

(* Format percentage nicely *)
pct[num_, den_] := If[den > 0, NumberForm[100.0*num/den, {4, 2}], Missing["NA"]];

(* Normalize file base name for pairing *)
niceName[path_, tag_] := Module[{b = FileBaseName[path]},
  StringReplace[b, {
    "_E+I" -> "", "_E-Only" -> "", "_E_only" -> "", "_EOnly" -> "",
    "_E" -> "", tag -> ""
  }]
];

(* pick the main summary table: prefer files whose name contains "stability" *)
pickSummaryFile[asc_] := Module[
  {keys = Keys@asc, hits},
  hits = Select[keys, StringContainsQ[#, 
           {"stability", "metrics__stability", "stability__cls", "metrics_stability"},
           IgnoreCase -> True] &];
  If[hits =!= {}, 
     First@MaximalBy[hits, Length@toDS@asc[#] &],
     (* fallback: among all CSVs, choose the one that actually has stable/lock/E/X *)
     First@MaximalBy[keys, Module[{ds = toDS@asc[#]},
       Which[
         !MatchQ[ds, _Dataset] || Length@ds == 0, -Infinity,
         True,
           10*Boole@AnyTrue[{"stable","is_stable","stable_flag","stable_cls","stability"}, colExistsQ[ds, #] &] +
           10*Boole@AnyTrue[{"lock_epoch","lockin_epoch","lock_ep","lock_step","lockin_step"}, colExistsQ[ds, #] &] +
            Boole@AnyTrue[{"E","e"}, colExistsQ[ds, #] &] +
            Boole@AnyTrue[{"X","x","E_times_I","E_mul_I"}, colExistsQ[ds, #] &] +
            Log[1+Length@ds]
       ]
     ] &]
  ]
];

(* Column name variants *)
stableCol = tryCols[#, {"stable","is_stable","stable_flag","stable_cls","stability"}] &;
lockCol   = tryCols[#, {"lock_epoch","lockin_epoch","lock_ep","lock_step","lockin_step"}] &;
xCol      = tryCols[#, {"X","x","E_times_I","E_mul_I"}] &;
eCol      = tryCols[#, {"E","e"}] &;
tCol      = tryCols[#, {"time_step","t","step","epoch"}] &;
geCol     = tryCols[#, {"global_entropy","entropy_global","H_global","entropy"}] &;

(* Calculate the binned stability curve *)
binStats[ds_, var_, nbins_:40] := Module[
  {
    varname = ToString[var], 
    v, st, data, min, max, edges, idx, grp, means
  },
  v  = tryCols[ds, {varname}];
  st = tryCols[ds, {"stable","is_stable","stable_flag","stable_cls","stability"}];
  If[MissingQ[v] || MissingQ[st], Return[Missing["NoData"]]];
  data = Cases[Transpose[{Normal@v, Normal@st}], {x_?NumericQ, y_?NumericQ}];
  If[data === {}, Return[Missing["NoData"]]];
  {min, max} = {Min[data[[All,1]]], Max[data[[All,1]]]};
  If[!NumericQ[min] || !NumericQ[max] || min==max, Return[Missing["NoData"]]];
  edges = Subdivide[min, max, nbins];
  idx   = Clip[Floor@Rescale[data[[All,1]], {min, max}, {1, nbins}], {1, nbins}];
  grp   = GroupBy[Transpose[{idx, data[[All,2]]}], First -> Last];
  means = Table[If[KeyExistsQ[grp,i], Mean@grp[i], Missing["NA"]], {i,1,nbins}];
  Dataset @ Table[
    <|"bin"->i, "edge_min"->edges[[i]], "edge_max"->edges[[i+1]], "stability_rate"->means[[i]]|>,
    {i,1,nbins}
  ]
];

(* ============================= *)
(* 3) LOAD AND PAIR FILES        *)
(* ============================= *)

filesA = FileNames["*.csv", dirA, Infinity];
filesB = FileNames["*.csv", dirB, Infinity];

assocA = AssociationMap[safeImport, filesA];
assocB = AssociationMap[safeImport, filesB];

(* Match files by normalized key *)
keyA = AssociationThread[niceName[#, "A"] & /@ Keys[assocA] -> Keys[assocA]];
keyB = AssociationThread[niceName[#, "B"] & /@ Keys[assocB] -> Keys[assocB]];

commonKeys = Intersection[Keys[keyA], Keys[keyB]];

say["File Loading Summary"];
Grid[{
  {"A (E+I) files found", Length[assocA]},
  {"B (E-only) files found", Length[assocB]},
  {"Matched file pairs", Length[commonKeys]}
}, Frame -> All]

(* Debug: show which files were picked *)
say["Chosen files"];
sumAfile   = pickSummaryFile[assocA];
sumBfile   = pickSummaryFile[assocB];
Print["Summary A: ", sumAfile];
Print["Summary B: ", sumBfile];

timeAfile = SelectFirst[Keys@assocA, StringContainsQ[#, {"timeseries","time_series","fl_timeseries"}, IgnoreCase->True] &];
timeBfile = SelectFirst[Keys@assocB, StringContainsQ[#, {"timeseries","time_series","fl_timeseries"}, IgnoreCase->True] &];
Print["Timeseries A: ", timeAfile];
Print["Timeseries B: ", timeBfile];

coldAfile = SelectFirst[Keys@assocA, StringContainsQ[#, {"cmb_coldspots","coldspot","cold_spot"}] &];
coldBfile = SelectFirst[Keys@assocB, StringContainsQ[#, {"cmb_coldspots","coldspot","cold_spot"}] &];
Print["Coldspots A: ", coldAfile];
Print["Coldspots B: ", coldBfile];

featAfile = SelectFirst[Keys@assocA, StringContainsQ[#, {"feat_importance","feature_importance"}] &];
featBfile = SelectFirst[Keys@assocB, StringContainsQ[#, {"feat_importance","feature_importance"}] &];
Print["FeatImp A: ", featAfile];
Print["FeatImp B: ", featBfile];

(* ============================= *)
(* 4) STABILITY & LOCK-IN ANALYSIS *)
(* ============================= *)

stabilitySummary[ds_] := Module[
    {stableCol, lockCol, n, nStable, nLock, rateStable, rateLock},
    n = Length[ds];
    stableCol = tryCols[ds, {"stable", "is_stable", "stable_flag"}];
    nStable = If[MissingQ[stableCol], Missing["NA"], Total@Boole[Normal@stableCol == 1]];
    lockCol = tryCols[ds, {"lock_epoch", "lockin_epoch", "lock_ep"}];
    nLock = If[MissingQ[lockCol], Missing["NA"], Total@Boole[Normal@lockCol >= 0]];
    rateStable = If[MissingQ[nStable] || n == 0, Missing["NA"], 100.0*nStable/n];
    rateLock = If[MissingQ[nLock] || n == 0, Missing["NA"], 100.0*nLock/n];
    <|"n" -> n, "stable_n" -> nStable, "stable_pct" -> rateStable,
      "lockin_n" -> nLock, "lockin_pct" -> rateLock|>
];

say["1) Overall stability / lock-in"];

sumAfile = pickSummaryFile[assocA];
sumBfile = pickSummaryFile[assocB];

sumA = If[MissingQ[sumAfile], Missing["NA"], assocA[sumAfile] // toDS];
sumB = If[MissingQ[sumBfile], Missing["NA"], assocB[sumBfile] // toDS];

If[MatchQ[sumA, _Dataset] && Length[sumA] > 0, Print["Cols in Summary A: ", Keys@Normal@First@sumA]];
If[MatchQ[sumB, _Dataset] && Length[sumB] > 0, Print["Cols in Summary B: ", Keys@Normal@First@sumB]];

stabA = If[MissingQ[sumA], Missing["NA"], stabilitySummary[sumA]];
stabB = If[MissingQ[sumB], Missing["NA"], stabilitySummary[sumB]];

Grid[{
    {"Metric", "E+I (A)", "E-only (B)"},
    {"Total Universes", stabA["n"], stabB["n"]},
    {"Stable Count / %", Row[{stabA["stable_n"], " / ", NumberForm[stabA["stable_pct"], {4, 2}], "%"}],
                        Row[{stabB["stable_n"], " / ", NumberForm[stabB["stable_pct"], {4, 2}], "%"}]},
    {"Lock-in Count / %", Row[{stabA["lockin_n"], " / ", NumberForm[stabA["lockin_pct"], {4, 2}], "%"}],
                        Row[{stabB["lockin_n"], " / ", NumberForm[stabB["lockin_pct"], {4, 2}], "%"}]}
}, Frame -> All]

(* ============================= *)
(* 5) GOLDILOCKS ZONE ANALYSIS   *)
(* ============================= *)

say["2) Goldilocks zone (A: X, B: E)"];

goldA = If[MissingQ[sumA], Missing["NA"], binStats[sumA, "X", 40]];
goldB = If[MissingQ[sumB], Missing["NA"], binStats[sumB, "E", 40]];

(* Compare peaks of the stability curves *)
peakInfo[ds_] := If[MissingQ[ds], Missing["NA"],
  Module[{tbl = Normal@ds // DeleteMissing},
    If[tbl === {} || !AssociationQ@First@tbl, Missing["NA"],
      First@Reverse@SortBy[tbl, Lookup[#, "stability_rate", -Infinity] &]
    ]
  ]
];

peakA = peakInfo[goldA];
peakB = peakInfo[goldB];

Grid[
    {
        {"Dataset", "Peak stability", "At (edge_min..edge_max)"},
        {"E+I (X)", If[MissingQ[peakA], "NA", NumberForm[100*peakA["stability_rate"], {4, 2}]~StringJoin~"%"],
                    If[MissingQ[peakA], "NA", Row[{NumberForm[peakA["edge_min"], {4, 3}], " .. ", NumberForm[peakA["edge_max"], {4, 3}]}]]},
        {"E-only (E)", If[MissingQ[peakB], "NA", NumberForm[100*peakB["stability_rate"], {4, 2}]~StringJoin~"%"],
                      If[MissingQ[peakB], "NA", Row[{NumberForm[peakB["edge_min"], {4, 3}], " .. ", NumberForm[peakB["edge_max"], {4, 3}]}]]}
    },
    Frame -> All
]

(* ============================= *)
(* 6) CMB ANOMALIES (COLD SPOT)   *)
(* ============================= *)

say["3) CMB cold-spots"];

pickColdFile[asc_] := SelectFirst[Keys@asc, 
  StringContainsQ[#, {"cmb_coldspots", "coldspots_summary", "coldspot", "cold_spot"}, IgnoreCase->True] &];
coldA = With[{f = pickColdFile[assocA]}, If[MissingQ[f], Missing["NA"], assocA[f]//toDS]];
coldB = With[{f = pickColdFile[assocB]}, If[MissingQ[f], Missing["NA"], assocB[f]//toDS]];

coldStats[ds_] := Module[{z = tryCols[ds, {"z_value", "z", "depth_uK", "depth_microK"}]},
    If[MissingQ[z], <|"count"->0, "min"->Missing["NA"], "mean"->Missing["NA"], "median"->Missing["NA"], "below_-70"->Missing["NA"]|>,
      With[{v = Normal@z // DeleteMissing},
        <|"count" -> Length[v],
          "min" -> Min[v],
          "mean" -> Mean[v],
          "median" -> Median[v],
          "below_-70" -> Count[v, x_ /; x <= -70] (* µK threshold *)
        |>
      ]
    ]
];

cA = If[MissingQ[coldA], <||>, coldStats[coldA]];
cB = If[MissingQ[coldB], <||>, coldStats[coldB]];

Grid[{
    {"Metric", "E+I (A)", "E-only (B)"},
    {"Total Spots Found", cA["count"], cB["count"]},
    {"Deepest Spot (µK or z)", cA["min"], cB["min"]},
    {"Average Depth", cA["mean"], cB["mean"]},
    {"Median Depth", cA["median"], cB["median"]},
    {"Count ≤ -70 µK", cA["below_-70"], cB["below_-70"]}
}, Frame -> All]

(* ============================= *)
(* 7) “BEST UNIVERSE” POST-LOCK NOISE *)
(* ============================= *)

say["4) Best-universe post-lock entropy noise"];

(* Find time series files and measure the std dev of global_entropy after lock_epoch *)
pickTimeSeries[asc_] := SelectFirst[Keys@asc, StringContainsQ[#, {"timeseries", "time_series"}] &, Missing["NA"]];
timeA = With[{f = pickTimeSeries[assocA]}, If[MissingQ[f], Missing["NA"], assocA[f]//toDS]];
timeB = With[{f = pickTimeSeries[assocB]}, If[MissingQ[f], Missing["NA"], assocB[f]//toDS]];

postLockStd[ds_] := Module[
    {lock = tryCols[ds, {"lock_epoch", "lockin_epoch", "lock_ep"}],
      ge = tryCols[ds, {"global_entropy","entropy_global","H_global"}],
      t = tryCols[ds, {"time_step","t","step"}]},
    If[Or[MissingQ[lock], MissingQ[ge], MissingQ[t]], Missing["NA"],
      Module[{lv = First@Normal@DeleteMissing@lock, tt = Normal@t, gg = Normal@ge},
        If[!NumericQ[lv], Missing["NA"],
          With[{mask = Boole[tt >= lv]},
            If[Total@mask < 5, Missing["NA"], StandardDeviation@Pick[gg, mask, 1]]
          ]
        ]
      ]
    ]
];

stdA = If[MissingQ[timeA], Missing["NA"], postLockStd[timeA]];
stdB = If[MissingQ[timeB], Missing["NA"], postLockStd[timeB]];

Grid[{
    {"Dataset", "Post-lock std(global_entropy)"},
    {"E+I (A)", stdA},
    {"E-only (B)", stdB}
}, Frame -> All]

(* ============================= *)
(* 8) XAI FEATURE IMPORTANCE     *)
(* ============================= *)

say["5) XAI feature importance"];

pickFeatImp[asc_] := SelectFirst[Keys@asc, StringContainsQ[#, {"feat_importance", "feature_importance"}] &, Missing["NA"]];
fiA = With[{f = pickFeatImp[assocA]}, If[MissingQ[f], Missing["NA"], assocA[f]//toDS]];
fiB = With[{f = pickFeatImp[assocB]}, If[MissingQ[f], Missing["NA"], assocB[f]//toDS]];

topK[ds_, k_:3] := Module[
    {score = tryCols[ds, {"importance","gain","weight","score"}],
      name = tryCols[ds, {"feature","name"}]},
    If[MissingQ[score] || MissingQ[name], Dataset[{}],
      Dataset @ TakeLargestBy[
        Thread[Rule[Normal@name, Normal@score]] // Normal,
        Last, UpTo[k]
      ]
    ]
];

Grid[{
    {"Top-3 Features (E+I)", topK[fiA, 3]},
    {"Top-3 Features (E-only)", topK[fiB, 3]}
}]

(* ============================= *)
(* 9) FINETUNE METRICS           *)
(* ============================= *)

say["6) Fine-tuning metrics (if available)"];

pickFinetune[asc_] := Select[Keys@asc, StringContainsQ[#, {"finetune", "fine_tune"}] &];
ftA = toDS /@ (assocA /@ pickFinetune[assocA]);
ftB = toDS /@ (assocB /@ pickFinetune[assocB]);

summFT[ds_] := Module[
    {acc = tryCols[ds, {"acc","accuracy","val_acc"}],
      auc = tryCols[ds, {"auc","roc_auc","val_auc"}]},
    <|"best_acc" -> If[MissingQ[acc], Missing["NA"], Max@Normal@acc],
      "best_auc" -> If[MissingQ[auc], Missing["NA"], Max@Normal@auc]|>
];

ftARes = If[ftA === {}, <||>, AssociationThread[Range@Length@ftA -> (summFT /@ ftA)]];
ftBRes = If[ftB === {}, <||>, AssociationThread[Range@Length@ftB -> (summFT /@ ftB)]];

Grid[{
    {"Finetune Metrics (E+I)", ftARes},
    {"Finetune Metrics (E-only)", ftBRes}
}, Frame -> All]

(* ============================= *)
(* 10) FINAL CONCLUSION OUTLINE  *)
(* ============================= *)

say["Summary notes for final interpretation:"];
Column@{
    "- Stability: compare A vs B table above (higher/lower).",
    "- Lock-in: compare percentages.",
    "- Goldilocks: compare peak stability && location (X vs E).",
    "- Cold spots: min/mean/median and ≤-70 count difference.",
    "- Best universe: post-lock std(global_entropy) lower ⇒ ‘cleaner’ stability.",
    "- XAI: compare top-3 features (multi-factor in A vs E-only).",
    "- Finetune: best AUC/ACC differences if present."
}

(* ============================= *)
(* 11) SAVE RESULTS TO DISK      *)
(* ============================= *)

say["11) Saving results to disk"];

(* --- Safe output dir, even if the notebook isn't saved --- *)
nbDir   = Quiet@NotebookDirectory[];
baseDir = If[StringQ[nbDir], nbDir, FileNameJoin[{$HomeDirectory, "Desktop"}]];
outDir  = FileNameJoin[{baseDir, "TQE_Wolfram_Analysis_Output"}];
If[!DirectoryQ[outDir],
  CreateDirectory[outDir, CreateIntermediateDirectories -> True]
];

(* 11.1 Save stability comparison as CSV *)
Export[FileNameJoin[{outDir, "stability_comparison.csv"}],
  {
    {"Metric", "E+I (A)", "E-only (B)"},
    {"Total Universes", stabA["n"], stabB["n"]},
    {"Stable %", stabA["stable_pct"], stabB["stable_pct"]},
    {"Lock-in %", stabA["lockin_pct"], stabB["lockin_pct"]}
  }
];

(* 11.2 Save Goldilocks peaks as JSON *)
Export[FileNameJoin[{outDir, "goldilocks_peaks.json"}],
  <|"E+I" -> peakA, "E-only" -> peakB|>
];

(* 11.3 Save cold-spot statistics as JSON *)
CleanForJSON[x_] := x /. Missing[_] -> Null;

Export[FileNameJoin[{outDir, "goldilocks_peaks.json"}],
  CleanForJSON@<|"E+I" -> peakA, "E-only" -> peakB|>
];

Export[FileNameJoin[{outDir, "coldspot_stats.json"}],
  CleanForJSON@<|"E+I" -> cA, "E-only" -> cB|>
];

Export[FileNameJoin[{outDir, "xai_top_features.json"}],
  CleanForJSON@<|"E+I" -> Normal@topK[fiA,3], "E-only" -> Normal@topK[fiB,3]|>
];

(* 11.4 Save Best Universe entropy stddev as CSV *)
Export[FileNameJoin[{outDir, "best_universe_entropy.csv"}],
  {
    {"Dataset","Post-lock std(global_entropy)"},
    {"E+I (A)", stdA},
    {"E-only (B)", stdB}
  }
];

(* 11.5 Save XAI top features as JSON *)
Export[FileNameJoin[{outDir, "xai_top_features.json"}],
  <|"E+I" -> Normal@topK[fiA,3], "E-only" -> Normal@topK[fiB,3]|>
];

say["Results exported to: " <> outDir];
