SPDX-License-Identifier: MIT

Copyright (c) 2025 Stefan Len

[![CI](https://github.com/SteviLen420/TQE_simulation/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/SteviLen420/TQE_simulation/actions/workflows/ci.yml)
[![Python](https://img.shields.io/badge/python-3.9%20|%203.10%20|%203.11-blue)](https://www.python.org/doc/)

# TQE Wolfram Analysis Pipeline
### Author: Stefan Len

## Abstract
This project is a suite of Wolfram Language notebooks designed to process, validate, aggregate, and compare data generated by the TQE (Theory of the Question of Existence) simulation framework. The pipeline's purpose is to take raw `.csv` outputs, perform a basic statistical "health check," summarize the results for two primary simulation types (`E+I` and `E_only`), and finally, produce a quantitative comparative analysis between them.

This workflow ensures data quality and consistency, and automates the calculation of global statistics and the comparison of experimental results.

## The Full Analysis Pipeline Overview
The project consists of four distinct but sequential notebooks that form a complete data processing chain.
```bash
graph TD;
    A[Raw .csv Files from Simulation] --> B{1. Data Validation};
    B -- Validated JSON data --> C{2. Statistics Aggregation};
    C -- "E+I" data --> D["EI_global_avg.json"];
    C -- "E_only" data --> E["E_only_global_avg.json"];
    D --> F{3. Comparative Analysis};
    E --> F;
    F --> G[Final Comparison Report (.csv, .json)];

    subgraph "Scripts"
        B(TQE_Wolfram_Math_Check_Pipeline.nb);
        C(TQE_Wolfram_EI_Math_Check_Summary_All_JSON.nb<br>TQE_Wolfram_E_Only_Math_Check_Summary_All_JSON.nb);
        F(TQE_Wolfram_Comparison_EI_vs_E_only.nb);
    end
```

## Requirements
Software: Wolfram Mathematica 12.0 or newer.

## The Pipeline Steps
### Step 1: Initial Data Validation
* **Script**: `TQE_Wolfram_Math_Check_Pipeline.nb`

* **Input**: A directory containing all raw `.csv` files from a single TQE simulation run.

* **Process**: The script iterates through all CSV files, calculating basic descriptive statistics (Mean, Standard Deviation) for all numeric columns. It also checks for data integrity issues, such as empty files, non-numeric values (`NaN`), or infinities.

* **Output**: A timestamped folder (`TQE_Math_Check_[timestamp]`) on the user's Desktop, containing the full analysis results in `math_check_results.csv` and `math_check_results.json` formats.

### Step 2: Aggregation of Global Statistics
* **Scripts**:

* `TQE_Wolfram_EI_Math_Check_Summary_All_JSON.nb`

* `TQE_Wolfram_E_Only_Math_Check_Summary_All_JSON.nb`

* **Input**: The `math_check_results.json` files generated in Step 1. The two scripts should be run in parallel on the data from the two different simulation types (`E+I` and `E_only`).

* **Process**: The scripts read all relevant JSON files, flatten the data into a long-form table (where each row represents a file/column/statistic), and then group by column to compute global averages (`GlobalMean`, `GlobalStdDev`) across all files.

* **Output**: Two key JSON files containing the global averages:

* `EI_global_avg.json`

* `E_only_global_avg.json`

### Step 3: Comparative Analysis
* **Script**: `TQE_Wolfram_Comparison_EI_vs_E_only.nb`

* **Input**: The `EI_global_avg.json` and `E_only_global_avg.json` files created in Step 2.

* **Process**: The script loads the two global average JSON files, aligns them by metric (column name), and computes the difference between their `GlobalMean values`.

* **Output**: A new, timestamped folder (`EI_vs_Eonly_Comparison_[timestamp]`) on the user's Desktop, containing the final comparison table in both `.csv` and `.json` formats.

### Execution Guide
To execute the full analysis pipeline, follow these steps:

### 1. Run the Data Validation:

* Open the `TQE_Wolfram_Math_Check_Pipeline.nb` notebook.

* Set the `simDir` variable to the absolute path of the directory containing your raw `.csv` files.

* Evaluate the entire notebook. Repeat this process for both the `E+I` and `E_only` simulation data.

### 2. Organize the Results:

* Create two separate folders, e.g., `math_check_results_EI_JSON` and `math_check_results_E_only_JSON`.

* Copy the `math_check_results.json` files generated in Step 1 into their corresponding folders.

### 3. Run the Aggregation:

* Open `TQE_Wolfram_EI_Math_Check_Summary_All_JSON.nb`. Set the `rootEI` variable to the path of the `math_check_results_EI_JSON` folder, then run the notebook.

* Open `TQE_Wolfram_E_Only_Math_Check_Summary_All_JSON.`. Set the `rootEonly` variable to the path of the `math_check_results_E_only_JSON` folder, then run the notebook.

### 4. Run the Comparison:

* Open the `TQE_Wolfram_Comparison_EI_vs_E_only.nb` notebook.

* Set the `eiFile` and `eonlyFile` variables to the paths of the `EI_global_avg.json` and `E_only_global_avg.json` files generated in Step 3.

* Evaluate the entire notebook to generate the final comparison report.

## License
This project is licensed under the MIT License â€“ see the [LICENSE](..../LICENSE) file for details.

## Contact

Got questions, ideas, or feedback?  
Drop me an email at **tqe.simulation@gmail.com** 
    
[RESULTS](..../RESULTS)
